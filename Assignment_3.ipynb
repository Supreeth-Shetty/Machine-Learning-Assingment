{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0f1f4a0",
   "metadata": {},
   "source": [
    "### 1.Explain the term machine learning, and how does it work? Explain two machine learning applications in the business world. What are some of the ethical concerns that machine learning applications could raise?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae75515",
   "metadata": {},
   "source": [
    "Ans : Machine learning is a data analytics technique that teaches computers to do what comes naturally to humans and animals: learn from experience. Machine learning algorithms use computational methods to “learn” information directly from data without relying on a predetermined equation as a mode\n",
    "\n",
    "#### Machine Learing applications are\n",
    "\n",
    "* employee monitoring and administration\n",
    "\n",
    "* government\n",
    "\n",
    "* agriculture\n",
    "\n",
    "* sustainable development\n",
    "\n",
    "* science\n",
    "\n",
    "* insurance\n",
    "\n",
    "* energy and utilities\n",
    "\n",
    "* communications, media and entertainment\n",
    "\n",
    "* retail and wholesale trade\n",
    "\n",
    "* manufacturing and natural resources, etc\n",
    "\n",
    "\n",
    "#### Ethical concerns that machine learning applications could raise are as follows\n",
    "\n",
    "* Cost to innovation\n",
    "\n",
    "* Harm to physical integrity\n",
    "\n",
    "* Lack of access to public services\n",
    "\n",
    "* Lack of trust\n",
    "\n",
    "* “Awakening” of AI\n",
    "\n",
    "* Security problems\n",
    "\n",
    "* Lack of quality data\n",
    "\n",
    "* Disappearance of jobs\n",
    "\n",
    "* Power asymmetries\n",
    "\n",
    "* Negative impact on health\n",
    "\n",
    "* Problems of integrity\n",
    "\n",
    "* Lack of accuracy of data\n",
    "\n",
    "* Lack of privacy\n",
    "\n",
    "* Lack of transparency\n",
    "\n",
    "* Potential for military use\n",
    "\n",
    "* Lack of informed consent\n",
    "\n",
    "* Bias and discrimination\n",
    "\n",
    "* Unfairness\n",
    "\n",
    "* Unequal power relations\n",
    "\n",
    "* Misuse of personal data\n",
    "\n",
    "* Negative impact on justice system\n",
    "\n",
    "* Negative impact on democracy\n",
    "\n",
    "* Potential for criminal and malicious use\n",
    "\n",
    "* Loss of freedom and individual autonomy\n",
    "\n",
    "* Contested ownership of data\n",
    "\n",
    "* Reduction of human contact\n",
    "\n",
    "* Problems of control and use of data and systems\n",
    "\n",
    "* Lack of accuracy of predictive recommendations\n",
    "\n",
    "* Lack of accuracy of non-individual recommendations\n",
    "\n",
    "* Concentration of economic power\n",
    "\n",
    "* Violation of fundamental human rights in supply chain\n",
    "\n",
    "* Violation of fundamental human rights of end users\n",
    "\n",
    "* Unintended, unforeseeable adverse impacts\n",
    "\n",
    "* Prioritisation of the “wrong” problems\n",
    "\n",
    "* Negative impact on vulnerable groups\n",
    "\n",
    "* Lack of accountability and liability\n",
    "\n",
    "* Negative impact on environment\n",
    "\n",
    "* Loss of human decision-making\n",
    "\n",
    "* Lack of access to and freedom of information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed42d5a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efa0c387",
   "metadata": {},
   "source": [
    "### 2. Describe the process of human learning:\n",
    "i. Under the supervision of experts\n",
    "\n",
    "ii. With the assistance of experts in an indirect manner\n",
    "\n",
    "iii. Self-education\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d816b940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92448cc6",
   "metadata": {},
   "source": [
    "### 3. Provide a few examples of various types of machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02657a4",
   "metadata": {},
   "source": [
    "Ans There are three types of machine learning: \n",
    "* Supervised learning,\n",
    "    * Some popular examples of supervised machine learning algorithms are: Linear regression for regression problems. Random forest for classification and regression problems. Support vector machines for classification problems.\n",
    "* Unsupervised learning\n",
    "    * In contrast to supervised learning, unsupervised learning methods are suitable when the output variables (i.e the labels) are not provided. ... Some examples of unsupervised learning algorithms include K-Means Clustering, Principal Component Analysis and Hierarchical Clustering\n",
    "* Reinforcement learning\n",
    "    * Reinforcement learning is an area of Machine Learning. ... In the absence of a training dataset, it is bound to learn from its experience. Example: The problem is as follows: We have an agent and a reward, with many hurdles in between. The agent is supposed to find the best possible path to reach the reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f826e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97e4e5a1",
   "metadata": {},
   "source": [
    "### 4. Examine the various forms of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8278e603",
   "metadata": {},
   "source": [
    "Ans There are three types of machine learning: \n",
    "* Supervised learning,\n",
    "    * Some popular examples of supervised machine learning algorithms are: Linear regression for regression problems. Random forest for classification and regression problems. Support vector machines for classification problems.\n",
    "* Unsupervised learning\n",
    "    * In contrast to supervised learning, unsupervised learning methods are suitable when the output variables (i.e the labels) are not provided. ... Some examples of unsupervised learning algorithms include K-Means Clustering, Principal Component Analysis and Hierarchical Clustering\n",
    "* Reinforcement learning\n",
    "    * Reinforcement learning is an area of Machine Learning. ... In the absence of a training dataset, it is bound to learn from its experience. Example: The problem is as follows: We have an agent and a reward, with many hurdles in between. The agent is supposed to find the best possible path to reach the reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b7da4f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d4cc65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69c5f857",
   "metadata": {},
   "source": [
    "### 5. Can you explain what a well-posed learning problem is? Explain the main characteristics that must be present to identify a learning problem properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a36b0ee",
   "metadata": {},
   "source": [
    "Ans : **Well Posed Learning Problem** – A computer program is said to learn from experience E in context to some task T and some performance measure P, if its performance on T, was measured by P, and it upgrades with experience E. \n",
    "\n",
    "Any problem can be segregated as well-posed learning problem if it has three characteristics – \n",
    "* Task\n",
    "* Performance Measure \n",
    "* Experience "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfc5ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18151d35",
   "metadata": {},
   "source": [
    "### 6. Is machine learning capable of solving all problems? Give a detailed explanation of your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96916021",
   "metadata": {},
   "source": [
    "Ans :\n",
    "While it is undeniable that AI has opened up a wealth of promising opportunities, it has also led to the emergence of a mindset that can be best described as “AI solutionism”. This is the philosophy that, given enough data, machine learning algorithms can solve all of humanity's problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ec89a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eeff35f3",
   "metadata": {},
   "source": [
    "### 7. What are the various methods and technologies for solving machine learning problems? Any two of them should be defined in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409a7b68",
   "metadata": {},
   "source": [
    "Common Machine Learning Algorithms are:\n",
    "* Linear Regression\n",
    "* Logistic Regression\n",
    "* Classification and Regression Trees\n",
    "* Naive Bayes\n",
    "* K-Nearest Neighbors (KNN)\n",
    "* Learning Vector Quantization (LVQ)\n",
    "* Support Vector Machines (SVM)\n",
    "* Random Forest\n",
    "* Boosting\n",
    "* AdaBoost\n",
    "\n",
    "### Linear Regression\n",
    "\n",
    "In the most simple words, Linear Regression is the supervised Machine Learning model in which the model finds the best fit linear line between the independent and dependent variable i.e it finds the linear relationship between the dependent and independent variable.\n",
    "\n",
    "Linear Regression is of two types: Simple and Multiple. Simple Linear Regression is where only one independent variable is present and the model has to find the linear relationship of it with the dependent variable\n",
    "\n",
    "Whereas, In Multiple Linear Regression there are more than one independent variables for the model to find the relationship.\n",
    "\n",
    "Equation of Simple Linear Regression, where bo is the intercept, b1 is coefficient or slope, x is the independent variable and y is the dependent variable.\n",
    "\n",
    "![Image of Yaktocat](https://cdn.analyticsvidhya.com/wp-content/uploads/2021/05/2.1.png)\n",
    "\n",
    "Equation of Multiple Linear Regression, where bo is the intercept, b1,b2,b3,b4…,bn are coefficients or slopes of the independent variables x1,x2,x3,x4…,xn and y is the dependent variable.\n",
    "\n",
    "![Image of Yaktocat](https://cdn.analyticsvidhya.com/wp-content/uploads/2021/05/2.2-300x39.png)\n",
    "\n",
    "\n",
    "Let’s understand this with the help of a diagram.\n",
    "![Image of Yaktocat](https://cdn.analyticsvidhya.com/wp-content/uploads/2021/05/2.3.png)\n",
    "\n",
    "\n",
    "In the above diagram,\n",
    "\n",
    "* x is our **dependent** variable which is plotted on the x-axis and y is the **dependent** variable which is plotted on the y-axis.\n",
    "* **Black** dots are the data points i.e the actual values.\n",
    "* **bo** is the intercept which is 10 and b1 is the slope of the x variable.\n",
    "* The **blue** line is the best fit line predicted by the model i.e the predicted values lie on the blue line.\n",
    "\n",
    "\n",
    "The vertical distance between the data point and the regression line is known as error or residual. Each data point has one residual and the sum of all the differences is known as the Sum of Residuals/Errors. \n",
    "\n",
    "Mathematical Approach:\n",
    "\n",
    "Residual/Error = Actual values – Predicted Values\n",
    "\n",
    "Sum of Residuals/Errors = Sum(Actual- Predicted Values)\n",
    "\n",
    "Square of Sum of Residuals/Errors = (Sum(Actual- Predicted Values))2\n",
    "\n",
    "i.e\n",
    "![Image of Yaktocat](https://cdn.analyticsvidhya.com/wp-content/uploads/2021/05/2.4.png)\n",
    "\n",
    "#### Assumptions of Linear Regression\n",
    "* **Linearity** : It states that the dependent variable Y should be linearly related to independent variables. This assumption can be checked by plotting a scatter plot between both variables.\n",
    "* **Normality**: The X and Y variables should be normally distributed. Histograms, KDE plots, Q-Q plots can be used to check the Normality assumption. \n",
    "* **Homoscedasticity**: The variance of the error terms should be constant i.e the spread of residuals should be constant for all values of X. This assumption can be checked by plotting a residual plot. If the assumption is violated then the points will form a funnel shape otherwise they will be constant.\n",
    "* **Independence/No Multicollinearity**: The variables should be independent of each other i.e no correlation should be there between the independent variables. To check the assumption, we can use a correlation matrix or VIF score. If the VIF score is greater than 5 then the variables are highly correlated.\n",
    "* The **error terms should be normally distributed.** Q-Q plots and Histograms can be used to check the distribution of error terms.\n",
    "* **No Autocorrelation**: The error terms should be independent of each other. Autocorrelation can be tested using the Durbin Watson test.\n",
    "\n",
    "\n",
    "**Evaluation Metrics for Regression Analysis**\n",
    "\n",
    "To understand the performance of the Regression model performing model evaluation is necessary. Some of the Evaluation metrics used for Regression analysis are:\n",
    "* **R squared or Coefficient of Determination**: The most commonly used metric for model evaluation in regression analysis is R squared. It can be defined as a Ratio of variation to the Total Variation. The value of R squared lies between 0 to 1, the value closer to 1 the better the model.\n",
    "\n",
    "![Image of Yaktocat](https://editor.analyticsvidhya.com/uploads/74264r2.png)\n",
    "\n",
    "* **Adjusted R squared**: It is the improvement to R squared. The problem/drawback with R2 is that as the features increase, the value of R2 also increases which gives the illusion of a good model. So the Adjusted R2 solves the drawback of R2. It only considers the features which are important for the model and shows the real improvement of the model.\n",
    "![Image of Yaktocat](https://editor.analyticsvidhya.com/uploads/80741adjusted%20r2.png)\n",
    "\n",
    "* **Mean Squared Error (MSE)**: Another Common metric for evaluation is Mean squared error which is the mean of the squared difference of actual vs predicted values.\n",
    "\n",
    "![Image of Yaktocat](https://editor.analyticsvidhya.com/uploads/42113mse.jpg)\n",
    "\n",
    "\n",
    "## Decision Tree\n",
    "\n",
    "Decision tree algorithm is one of the most versatile algorithms in machine learning which can perform both classification and regression analysis. It is very powerful and works great with complex datasets. Apart from that, it is very easy to understand and read. That makes it more popular to use. When coupled with ensemble techniques – which we will learn very soon- it performs even better.\n",
    "As the name suggests, this algorithm works by dividing the whole dataset into a tree-like structure based on some rules and conditions and then gives prediction based on those conditions.\n",
    "Let’s understand the approach to decision tree with a basic scenario. \n",
    "Suppose it’s Friday night and you are not able to decide if you should go out or stay at home. Let the decision tree decide it for you.\n",
    "\n",
    "\n",
    "<img src=\"images/Decision_tree1.PNG\" width=\"300\">\n",
    "                         \n",
    "Although we may or may not use the decision tree for such decisions, this was a basic example to help you understand how a decision tree makes a decision.\n",
    "So how did it work?\n",
    "*\tIt selects a root node based on a given condition, e.g. our root node was chosen as time >10 pm.\n",
    "*\tThen, the root node was split into child notes based on the given condition. The right child node in the above figure fulfilled the condition, so no more questions were asked.\n",
    "*\tThe left child node didn’t fulfil the condition, so again it was split based on a new condition.\n",
    "*\tThis process continues till all the conditions are met or if you have predefined the depth of your tree, e.g. the depth of our tree is 3, and it reached there when all the conditions were exhausted.\n",
    "\n",
    "Let’s see how the parent nodes and condition is chosen for the splitting to work.\n",
    "\n",
    "#### Decision Tree for Regression\n",
    "When performing regression with a decision tree, we try to divide the given values of X into distinct and non-overlapping regions, e.g. for a set of possible values X1, X2,..., Xp; we will try to divide them into J distinct and non-overlapping regions R1, R2, . . . , RJ.\n",
    "For a given observation falling into the region Rj, the prediction is equal to the mean of the response(y) values for each training observations(x) in the region Rj. \n",
    "The regions R1,R2, . . . , RJ  are selected in a way to reduce the following sum of squares of residuals :\n",
    "\n",
    "\n",
    "<img src=\"images/formula1.PNG\" width=\"300\">\n",
    "                                                        \n",
    "Where, yrj (second term) is the mean of all the response variables in the region ‘j’.\n",
    "\n",
    "\n",
    "\n",
    "#### Recursive binary splitting(Greedy approach)\n",
    "As mentioned above, we try to divide the X values into j regions, but it is very expensive in terms of computational time to try to fit every set of X values into j regions. Thus, decision tree opts for a top-down greedy approach in which nodes are divided into two regions based on the given condition, i.e. not every node will be split but the ones which satisfy the condition are split into two branches. It is called greedy because it does the best split at a given step at that point of time rather than looking for splitting a step for a better tree in upcoming steps. It decides a threshold value(say s) to divide the observations into different regions(j) such that the RSS for Xj>= s and Xj <s is minimum.\n",
    "\n",
    "\n",
    "<img src=\"images/formula2.PNG\" width=\"400\">\n",
    "                      \n",
    "Here for the above equation, j and s are found such that this equation has the minimum value.\n",
    "The regions R1, R2 are selected based on that value of s and j such that the equation above has the minimum value.\n",
    "Similarly, more regions are split out of the regions created above based on some condition with the same logic. This continues until a stopping criterion (predefined) is achieved.\n",
    "Once all the regions are split, the prediction is made based on the mean of observations in that region.\n",
    "\n",
    "The process mentioned above has a high chance of overfitting the training data as it will be very complex. \n",
    "\n",
    "#### Tree Pruning\n",
    "Tree pruning is the method of trimming down a full tree (obtained through the above process) to reduce the complexity and variance in the data. Just as we regularised linear regression, we can also regularise the decision tree model by adding a new term. \n",
    "\n",
    "\n",
    "<img src=\"images/formula3.PNG\" width=\"300\">\n",
    "                                       \n",
    "Where, T  is the subtree which is a subset of the full tree T0\n",
    "And α is the non-negative tuning parameter which penalises the MSE with an increase in tree length.\n",
    "By using cross-validation, such values of α and T are selected for which our model gives the lowest test error rate.\n",
    "This is how the decision tree regression model works. Let’s now see the working algorithm of doing classification using a decision tree.\n",
    "Greedy Algorithm\n",
    "As per Hands-on machine learning book “greedy algorithm greedily searches for an optimum split at the top level, then repeats the process at each level. It does not check whether or not the split will lead to the lowest possible impurity several levels down. A greedy algorithm often produces a reasonably good solution, but it is not guaranteed to be the optimal solution.”\n",
    "\n",
    "\n",
    "#### Post-pruning\n",
    "\n",
    "Post-pruning, also known as backward pruning, is the process where the decision tree is generated first and then the non-significant branches are removed. Cross-validation set of data is used to check the effect of pruning and tests whether expanding a node will make an improvement or not. If any improvement is there then we continue by expanding that node else if there is reduction in accuracy then the node not be expanded and should be converted in a leaf node.\n",
    "\n",
    "\n",
    "#### Pre-pruning\n",
    "\n",
    "Pre-pruning, also known as forward pruning, stops the non-significant branches from generating. It uses a condition to decide when should it terminate splitting of some of the branches prematurely as the tree is generated. \n",
    "\n",
    "\n",
    "### Classification Trees\n",
    "\n",
    "Regression trees are used for quantitative data. In the case of qualitative data or categorical data, we use classification trees.  In regression trees, we split the nodes based on RSS criteria, but in classification, it is done using classification error rate, Gini impurity and entropy.\n",
    "Let’s understand these terms in detail.\n",
    "\n",
    "#### Entropy\n",
    "Entropy is the measure of randomness in the data. In other words, it gives the impurity present in the dataset.\n",
    "\n",
    "<img src=\"images/entropy.PNG\" width=\"300\">\n",
    "                                           \n",
    "When we split our nodes into two regions and put different observations in both the regions, the main goal is to reduce the entropy i.e. reduce the randomness in the region and divide our data cleanly than it was in the previous node. If splitting the node doesn’t lead into entropy reduction, we try to split based on a different condition, or we stop. \n",
    "A region is clean (low entropy) when it contains data with the same labels and random if there is a mixture of labels present (high entropy).\n",
    "Let’s suppose there are ‘m’ observations and we need to classify them into categories 1 and 2.\n",
    "Let’s say that category 1 has ‘n’ observations and category 2 has ‘m-n’ observations.\n",
    "\n",
    "p= n/m  and    q = m-n/m = 1-p\n",
    "\n",
    "then, entropy for the given set is:\n",
    "\n",
    "\n",
    "          E = -p*log2(p) – q*log2(q) \n",
    "           \n",
    "           \n",
    "When all the observations belong to category 1, then p = 1 and all observations belong to category 2, then p =0, int both cases E =0, as there is no randomness in the categories.\n",
    "If half of the observations are in category 1 and another half in category 2, then p =1/2 and q =1/2, and the entropy is maximum, E =1.\n",
    "\n",
    "\n",
    "<img src=\"images/entropy1.PNG\" width=\"300\">\n",
    "                                  \n",
    "\n",
    "#### Information Gain\n",
    "Information gain calculates the decrease in entropy after splitting a node. It is the difference between entropies before and after the split. The more the information gain, the more entropy is removed. \n",
    "\n",
    "<img src=\"images/info_gain.PNG\" width=\"300\">\n",
    "\n",
    "                                 \n",
    "Where, T is the parent node before split and X is the split node from T.\n",
    "\n",
    "A tree which is splitted on basis of entropy and information gain value looks like:\n",
    "\n",
    "<img src=\"images/entropy_tree.PNG\" width=\"900\">\n",
    "\n",
    "#### Ginni Impurity\n",
    "According to wikipedia, ‘Gini impurity is a measure of how often a randomly chosen element from the set would be incorrectly labelled if it was randomly labelled according to the distribution of labels in the subset.’\n",
    "It is calculated by multiplying the probability that a given observation is classified into the correct class and sum of all the probabilities when that particular observation is classified into the wrong class.\n",
    "Let’s suppose there are k number of classes and an observation belongs to the class ‘i’, then Ginni impurity is given as:\n",
    "\n",
    "<img src=\"images/ginni.PNG\" width=\"300\">\n",
    "                                    \n",
    "Ginni impurity value lies between 0 and 1, 0 being no impurity and 1 denoting random distribution.\n",
    "The node for which the Ginni impurity is least is selected as the root node to split.\n",
    "\n",
    "\n",
    "A tree which is splitted on basis of ginni impurity value looks like:\n",
    "\n",
    "<img src=\"images/tree_example.PNG\" width=\"900\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12c1ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "901d72d4",
   "metadata": {},
   "source": [
    "### 8. Can you explain the various forms of supervised learning? Explain each one with an example application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b546f11b",
   "metadata": {},
   "source": [
    "Ans : Supervised Learning is the process of making an algorithm to learn to map an input to a particular output. This is achieved using the labelled datasets that you have collected. If the mapping is correct, the algorithm has successfully learned. Else, you make the necessary changes to the algorithm so that it can learn correctly. Supervised Learning algorithms can help make predictions for new unseen data that we obtain later in the future. \n",
    "\n",
    "This is similar to a teacher-student scenario. There is a teacher who guides the student to learn from books and other materials. The student is then tested and if correct, the student passes. Else, the teacher tunes the student and makes the student learn from the mistakes that he or she had made in the past. That is the basic principle of Supervised Learning.\n",
    "\n",
    "![Image of Yaktocat](https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2019/11/Unsupervised-Learning-e1574677751474-404x300.jpg)\n",
    "\n",
    "**Supervised Learning Algorithmss And Its Applications:**  \n",
    "\n",
    "* **Linear Regression** : Linear regressions can be used in business to evaluate trends and make estimates or forecasts.\n",
    "* **K Nearest Neighbor** : KNN can outperform more powerful classifiers and is used in a variety of applications such as economic forecasting, data compression and genetics\n",
    "* **Gaussian Naive Bayes** : It is mainly used in text classification that includes a high-dimensional training dataset.\n",
    "* **Decision Trees** : Decision trees are used for handling non-linear data sets effectively\n",
    "* **Support Vector Machine (SVM)** : SVM is used for classification, regression and outliers detection\n",
    "* **Random Forest** : Random forest has been used in a variety of applications, for example to provide recommendations of different products to customers in e-commerce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caff6964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb880ab1",
   "metadata": {},
   "source": [
    "### 9. What is the difference between supervised and unsupervised learning? With a sample application in each region, explain the differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e0dd3c",
   "metadata": {},
   "source": [
    "<img src=\"images/difference between supervised and unsupervised learning.PNG\" width=\"900\">\n",
    "\n",
    "**Suprevised Machine Learning Application**\n",
    "\n",
    "**Spam Detection**\n",
    "\n",
    "This program is used to block unreal or machine-based messages and e-mails. G-Mail has an algorithm that learns various keywords that may be incorrect. The One plus Messages App gives the user the task of letting the application know which keywords must be blocked and the keyword would block those messages from the app.\n",
    "\n",
    "**Unsuprevised Machine Learning Application**\n",
    "\n",
    "**Recommendation systems**\n",
    "\n",
    "Recommender systems, which involve grouping together users with similar viewing patterns in order to recommend similar content.\n",
    "\n",
    "\n",
    "**The Key diffrence in these two user cases are:**\n",
    "\n",
    "In Spam detection we have training dataset which is labeled and the algorithm learns based on the historic data and when the new datapoint comes in we algorithm try's to predict if the email recived spam or not, the output is based on the learning it had earlier.\n",
    "\n",
    "Where as in case of Recommendation system, The algoritm try's to form a groups based on the similarities in the datapoints in the dataset, So when the new datapoint comes in the datapoint based on the pattern it has, it will be added to one or the oter group whixh is already formed   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ad7230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8618ee04",
   "metadata": {},
   "source": [
    "### 10. Describe the machine learning process in depth.\n",
    "\n",
    "a. Make brief notes on any two of the following:\n",
    "\n",
    "    i. MATLAB is one of the most widely used programming languages.\n",
    "    \n",
    "    ii. Deep learning applications in healthcare\n",
    "\n",
    "    iii. Study of the market basket\n",
    "    \n",
    "    iv. Linear regression (simple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b4b965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a01b7931",
   "metadata": {},
   "source": [
    "11. Make a comparison between:-\n",
    "\n",
    "     1. Generalization and abstraction\n",
    "\n",
    "     2. Learning that is guided and unsupervised\n",
    "\n",
    "     3. Regression and classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19790a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
