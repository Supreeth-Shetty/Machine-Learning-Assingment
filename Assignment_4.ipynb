{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e767677",
   "metadata": {},
   "source": [
    "### 1. What are the key tasks involved in getting ready to work with machine learning modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e92253c",
   "metadata": {},
   "source": [
    "Ans : The Key tasks are : \n",
    "\n",
    "* **Data Gathering**: Any machine learning problem requires a lot of data for training/testing purposes. Identifying the right data sources and gathering data from these data sources is the key. Data could be found from databases, external agencies, the internet etc.\n",
    "* **Data Preprocessing**: Before starting training the models, it is of utmost importance to prepare data appropriately. As part of data preprocessing, some of the following is done:\n",
    "* **Data cleaning**: Data cleaning requires one to identify attributes having not enough data or attributes which are not having variance. These data (rows and columns) need to be removed from the training data set.\n",
    "* **Missing data imputation**: Handling missing data using data imputation techniques such as replacing missing data with mean, median, or mode. Here is my post on this topic: Replace missing values with mean, median or mode\n",
    "* **Exploratory Data Analysis (EDA)**: Once data is preprocessed, the next step is to perform exploratory data analysis to understand data distribution and relationships between/within the data. Some of the following are performed as part of EDA:\n",
    "    * Correlation analysis\n",
    "    * Multicollinearity analysis\n",
    "    * Data distribution analysis\n",
    "* **Feature Engineering:** Feature engineering is one of the critical tasks which would be used when building machine learning models. Feature engineering is important because selecting the right features would not only help build models of higher accuracy but also help achieve objectives related to building simpler models, reduce overfitting, etc. Feature engineering includes some of the tasks such as deriving features from raw features, identifying important features, feature extraction and feature selection. The following are some of the techniques which could be used for feature selection:\n",
    "    * Filter methods help in selecting features based on the outcomes of statistical tests. The following are some of the statistical tests which are used:\n",
    "        * Pearson’s correlation\n",
    "        * Linear discriminant analysis (LDA)\n",
    "        * Analysis of Variance (ANOVA)\n",
    "        * Chi-square tests\n",
    "    * Wrapper methods help in feature selection by using a subset of features and determining the model accuracy. The following are some of the algorithms used:\n",
    "        * Forward selection\n",
    "        * Backward elimination\n",
    "        * Recursive feature elimination\n",
    "    * Regularization techniques penalize one or more features appropriately to come up with most important features. The following are some of the algorithms used:\n",
    "        * LASSO (L1) regularization\n",
    "        * Ridge (L2) regularization\n",
    "        * Elastic net regularization\n",
    "        * Regularization with classification algorithms such as Logistic regression, SVM, etc.\n",
    "* **Training Models:** Once some of the features are determined, then comes training models with data related to those features. The following is a list of different types of machine learning problems and related algorithms which can be used to solve these problems:\n",
    "    * **Regression:** Regression tasks mainly deal with the estimation of numerical values (continuous variables). Some of the examples include estimation of housing price, product price, stock price etc. Some of the following ML methods could be used for solving regressions problems:\n",
    "        * Kernel regression (Higher accuracy)\n",
    "        * Gaussian process regression (Higher accuracy)\n",
    "        * Regression trees\n",
    "        * Linear regression\n",
    "        * Support vector regression\n",
    "        * LASSO / Ridge\n",
    "        * Deep learning\n",
    "        * Random forests\n",
    "    * Classification: Classification tasks is simply related to predicting a category of data (discrete variables). One of the most common examples is predicting whether or not an email if spam or ham. Some of the common use cases could be found in the area of healthcare such as whether a person is suffering from a particular disease or not. It also has its application in financial use cases such as determining whether a transaction is a fraud or not. You might want to check this page on real-world examples of classification models, machine learning classification models real-life examples. The ML methods such as the following could be applied to solve classification tasks:\n",
    "        * Kernel discriminant analysis (Higher accuracy)\n",
    "        * K-Nearest Neighbors (Higher accuracy)\n",
    "        * Artificial neural networks (ANN) (Higher accuracy)\n",
    "        * Support vector machine (SVM) (Higher accuracy)\n",
    "        * Random forests (Higher accuracy)\n",
    "        * Decision trees\n",
    "        * Boosted trees\n",
    "        * Logistic regression\n",
    "        * naive Bayes\n",
    "        * Deep learning\n",
    "    * **Clustering:** Clustering tasks are all about finding natural groupings of data and a label associated with each of these groupings (clusters). Some of the common examples include customer segmentation, product features identification for the product roadmap. Some of the following are common ML methods:\n",
    "        * Mean-shift  (Higher accuracy)\n",
    "        * Hierarchical clustering\n",
    "        * K-means\n",
    "        * Topic models\n",
    "* **Multivariate querying:** Multivariate querying is about querying or finding similar objects. Some of the following ML methods could be used for such problems:\n",
    "    * Nearest neighbors\n",
    "    * Range search\n",
    "    * Farthest neighbors\n",
    "* **Density estimation:** Density estimation problems are related to finding the likelihood or frequency of objects. In probability and statistics, density estimation is the construction of an estimate, based on observed data, of an unobservable underlying probability density function. Some of the following ML methods could be used for solving density estimation tasks:\n",
    "    * Kernel density estimation (Higher accuracy)\n",
    "    * Mixture of Gaussians\n",
    "    * Density estimation tree\n",
    "* **Dimensionality reduction (feature extraction):** As per the Wikipedia page on Dimension reduction, Dimension reduction is the process of reducing the number of random variables under consideration, and can be divided into feature selection and feature extraction. Following are some of ML methods that could be used for dimension reduction:\n",
    "    * Manifold learning/KPCA (Higher accuracy)\n",
    "    * Principal component analysis\n",
    "    * Independent component analysis\n",
    "    * Gaussian graphical models\n",
    "    * Non-negative matrix factorization\n",
    "    * Compressed sensing\n",
    "* **Model selection / Algorithm selection:** Many times, there are multiple models which are trained using different algorithms. One of the important tasks is to select the most optimal models for deploying them in production. Hyperparameter tuning is the most common task performed as part of model selection. Also, if there are two models trained using different algorithms which have similar performance, then one also needs to perform algorithm selection.\n",
    "* **Testing and matching:** Testing and matching tasks relate to comparing data sets. Following are some of the methods that could be used for such kinds of problems:\n",
    "    * Minimum spanning tree\n",
    "    * Bipartite cross-matching\n",
    "    * N-point correlation\n",
    "* **Model monitoring:** Once the models are trained and deployed, they require to be monitored at regular intervals. Monitoring models require the processing actual values and predicted values and measure the model performance based on appropriate metrics.\n",
    "* **Model retraining:** In case, the model performance degrades, the models are required to be retrained.  The following gets done as part of model retraining:\n",
    "    * New features get determined\n",
    "    * New algorithms can be used\n",
    "    * Hyperparameters can get tuned\n",
    "    * Model ensembles may get deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ecf39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69405db2",
   "metadata": {},
   "source": [
    "### 2. What are the different forms of data used in machine learning? Give a specific example for each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90195e7",
   "metadata": {},
   "source": [
    "Ans : Almost anything can be turned into DATA. Building a deep understanding of the different data types is a crucial prerequisite for doing Exploratory Data Analysis (EDA) and Feature Engineering for Machine Learning models. \n",
    "\n",
    "Most data can be categorized into 4 basic types from a Machine Learning perspective: \n",
    "* numerical data \n",
    "* categorical data \n",
    "* time-series data\n",
    "* text\n",
    "\n",
    "**Numerical data** can be characterized by continuous or discrete data. Continuous data can assume any value within a range whereas discrete data has distinct values.\n",
    "\n",
    "![Image of Yaktocat](https://miro.medium.com/max/401/1*lheLiN7y4sSD2JKvow-clw.jpeg)\n",
    "\n",
    "\n",
    "**Categorical data** represents characteristics, such as a hockey player’s position, team, hometown. Categorical data can take numerical values. For example, maybe we would use 1 for the colour red and 2 for blue. But these numbers don’t have a mathematical meaning. That is, we can’t add them together or take the average.\n",
    "\n",
    "An example would be class difficulty, such as beginner, intermediate, and advanced. Those three types of classes would be a way that we could label the classes, and they have a natural order in increasing difficulty.\n",
    "\n",
    "![Image of Yaktocat](https://miro.medium.com/max/229/1*wqUH7IOl8Hky5BI6RvoGtA.png)\n",
    "\n",
    "**Time series data** is a sequence of numbers collected at regular intervals over some period of time. It is very important, especially in particular fields like finance. Time series data has a temporal value attached to it, so this would be something like a date or a timestamp that you can look for trends in time.\n",
    "\n",
    "For example, we might measure the average number of home sales for many years. The difference of time series data and numerical data is that rather than having a bunch of numerical values that don’t have any time ordering, time-series data does have some implied ordering. There is a first data point collected and the last data point collected.\n",
    "\n",
    "![Image of Yaktocat](https://miro.medium.com/max/700/1*3H17aiABEWXRY_ZD5MG6fg.png)\n",
    "\n",
    "**Text data** is basically just words. A lot of the time the first thing that you do with text is you turn it into numbers using some interesting functions like the bag of words formulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44967812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c684c736",
   "metadata": {},
   "source": [
    "### 3. Distinguish:\n",
    "\n",
    "   1. Numeric vs. categorical attributes\n",
    "   2. Feature selection vs. dimensionality reduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61dc81a",
   "metadata": {},
   "source": [
    "Ans : \n",
    "### **Distinguish Numeric vs. categorical attributes**\n",
    "    \n",
    "**Key Differences Between Categorical & Numerical Data**\n",
    "\n",
    "**Definitions :** \n",
    "Categorical data is a type of data that is used to group information with similar characteristics while Numerical data is a type of data that expresses information in the form of numbers. It combines numeric values to depict relevant information while categorical data uses a descriptive approach to express information\n",
    "\n",
    "Examples\n",
    "\n",
    " Categorical data examples include personal biodata information—full name, gender, phone number, etc. Numerical data examples include CGPA calculator, interval sale, etc. \n",
    " \n",
    "**Types :**\n",
    "Categorical data is divided into two types, namely; nominal and ordinal data while numerical data is categorised into discrete and continuous data. Continuous data is now further divided into interval data and ratio data.\n",
    "\n",
    "**Data Characteristics :**\n",
    "The characteristics of **categorical data** include; lack of a standardized order scale, natural language description, takes numeric values with qualitative properties, and visualized using bar chart and pie chart. \n",
    "**Numerical data**, on the other hand, has a standardized order scale, numerical description, takes numeric values with numerical properties, and visualized using bar charts, pie charts, scatter plots, etc.\n",
    "\n",
    "**User-centred Design :**\n",
    "Numerical data collection method is more user-centred than categorical data. Most respondents do not want to spend a lot of time filling out forms or surveys which is why questionnaires used to collect numerical data has a lower abandonment rate compared to that of categorical data.\n",
    "\n",
    "**Data Collection Methods :**\n",
    "**Categorical data** can be collected through different methods, which may differ from categorical data types. For instance, nominal data is mostly collected using open-ended questions while ordinal data is mostly collected using multiple-choice questions.**Numerical data**, on the other hand, is mostly collected through multiple-choice questions. We observe that it is mostly collected using open-ended questions whenever there is a need for calculation.\n",
    "\n",
    "**Analysis & Interpretation :**\n",
    "There are 2 methods of performing **numerical data** analysis, namely; descriptive and inferential statistics. Some examples of these 2 methods include; measures of central tendency, turf analysis, text analysis, conjoint analysis, trend analysis, etc.There are also 2 methods of analyzing **categorical data**, namely; median and mode. In some cases, we see that ordinal data Is analyzed using univariate statistics, bivariate statistics, regression analysis, etc. which is used as an alternative to calculating mean and standard deviation.\n",
    "\n",
    "**Advantage :**\n",
    "\n",
    "Numerical data is compatible with most statistical analysis methods and as such makes it the most used among researchers. Categorical data, on the other hand, does not support most statistical analysis methods. \n",
    "\n",
    "There are alternatives to some of the statistical analysis methods not supported by categorical data. However, they can not give results that are as accurate as the original.\n",
    "\n",
    "**Disadvantage :**\n",
    "\n",
    "Numerical data analysis is mostly performed in a standardized or controlled environment, which may hinder a proper investigation. This is because natural factors that may influence the results have been eliminated, causing the results not to be completely accurate. \n",
    "\n",
    "Numerical data collection is also strictly based on the researcher's point of view, limiting the respondent's influence on the result. This is not the case with categorical data. \n",
    "\n",
    "Nominal data captures human emotions to an extent through open-ended questions. However, the setback with this is that the researcher may sometimes have to deal with irrelevant data.\n",
    "\n",
    "___________________________________________________________________________________________________________________________\n",
    "\n",
    "### **Distinguish Feature selection vs. dimensionality reduction**\n",
    "\n",
    "* feature selection: you select a subset of the original feature set; while\n",
    "* feature extraction: you build a new set of features from the original feature set.\n",
    "\n",
    "**Feature Selection**\n",
    "\n",
    "* Feature selection yields a subset of features from the original set of features, which are best representatives of the data. It is an exhaustive search.\n",
    "* In text data, features might be size of characters or some global features of the text. Feature selection will keep only certain features of those.\n",
    "* Feature selection is done in the context of an optimization problem.\n",
    "\n",
    "**Dimension Reduction**\n",
    "\n",
    "* Dimensionality reduction is generic and only depends on the data and not on what you plan to do with it.\n",
    "* Assuming a classification problem you select the features that will help you classify your data better, while a dimensionality reduction algorithm is unaware of this and just projects the data into a lower dimensionality space. That in turn can work quite well or not for your classification algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e1483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84d45ac8",
   "metadata": {},
   "source": [
    "### 4. Make quick notes on any two of the following:\n",
    "\n",
    "    1. The histogram\n",
    "    2. Use a scatter plot\n",
    "    3.PCA (Personal Computer Aid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624541a2",
   "metadata": {},
   "source": [
    "Ans : \n",
    "\n",
    "### The histogram\n",
    "\n",
    "A histogram is a graphical representation that organizes a group of data points into user-specified ranges. Similar in appearance to a bar graph, the histogram condenses a data series into an easily interpreted visual by taking many data points and grouping them into logical ranges or bins.\n",
    "\n",
    "**KEY TAKEAWAYS**\n",
    "\n",
    "A histogram is a bar graph-like representation of data that buckets a range of outcomes into columns along the x-axis.\n",
    "The y-axis represents the number count or percentage of occurrences in the data for each column and can be used to visualize data distributions.\n",
    "In trading, the MACD histogram is used by technical analysts to indicate changes in momentum.\n",
    "\n",
    "Example :\n",
    "\n",
    "![Image of Yaktocat](https://www.investopedia.com/thmb/iM-OWscIDJ31DrGOwwtdBXyIBUg=/660x0/filters:no_upscale():max_bytes(150000):strip_icc():format(webp)/Histogram2-3cc0e953cc3545f28cff5fad12936ceb.png)\n",
    "\n",
    "\n",
    "___________________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "### The Scatter Plot\n",
    "\n",
    "A scatter plot (aka scatter chart, scatter graph) uses dots to represent values for two different numeric variables. The position of each dot on the horizontal and vertical axis indicates values for an individual data point. Scatter plots are used to observe relationships between variables.\n",
    "\n",
    "**When you should use a scatter plot**\n",
    "\n",
    "Scatter plots’ primary uses are to observe and show relationships between two numeric variables. The dots in a scatter plot not only report the values of individual data points, but also patterns when the data are taken as a whole.\n",
    "\n",
    "![Image of Yaktocat](https://chartio.com/assets/5689fd/tutorials/charts/scatter-plots/a9b8dd5dc2057a70446e5aa32f32b49d54b55f5cabf17a4610e2da94bea7fed5/scatter-plot-example-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b586714a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "480bd7e5",
   "metadata": {},
   "source": [
    "### 5. Why is it necessary to investigate data? Is there a discrepancy in how qualitative and quantitative data are explored?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cdd476",
   "metadata": {},
   "source": [
    "Ans : This is common advice for many data scientists. If your data set is messy, building models will not help you to solve your problem. What will happen is “garbage in, garbage out.” In order to build a powerful machine learning algorithm. We need to explore and understand our data set before we define a predictive task and solve it.\n",
    "\n",
    "**The Key Concepts To Investigating Your Dataset**\n",
    "\n",
    "* Ask the right questions?\n",
    "* Analyze different subsets of data\n",
    "* Explore trends\n",
    "* Find your blind spots\n",
    "* Investigate the whys\n",
    "\n",
    "Yes there is discrepancy in how qualitative and quantitative data are explored, because the nature and orbjective of both the data are diffrent hence explored in diffrent way.\n",
    "\n",
    "<img src=\"images/how qualitative and quantitative data are explored.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729cca78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b265643",
   "metadata": {},
   "source": [
    "### 6. What are the various histogram shapes? What exactly are ‘bins'?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046050cf",
   "metadata": {},
   "source": [
    "Ans : The various histogram shapes are:\n",
    "\n",
    "* **Normal Distribution**\n",
    "\n",
    "    A common pattern is the bell-shaped curve known as the \"normal distribution.\" In a normal or \"typical\" distribution, points are as likely to occur on one side of the average as on the other. Note that other distributions look similar to the normal distribution. Statistical calculations must be used to prove a normal distribution.\n",
    "\n",
    "    It's important to note that \"normal\" refers to the typical distribution for a particular process. For example, many processes have a natural limit on one side and will produce skewed distributions. This is normal—meaning typical—for those processes, even if the distribution isn’t considered \"normal.\"\n",
    "    ![Image of Yaktocat](https://asq.org/-/media/Images/Learn-About-Quality/Histogram/dcat-histogram-normal.gif?la=en)\n",
    "\n",
    "\n",
    "* **Skewed Distribution**\n",
    "\n",
    "    The skewed distribution is asymmetrical because a natural limit prevents outcomes on one side. The distribution’s peak is off center toward the limit and a tail stretches away from it. For example, a distribution of analyses of a very pure product would be skewed, because the product cannot be more than 100 percent pure. Other examples of natural limits are holes that cannot be smaller than the diameter of the drill bit or call-handling times that cannot be less than zero. These distributions are called right- or left-skewed according to the direction of the tail.\n",
    "    ![Image of Yaktocat](https://asq.org/-/media/Images/Learn-About-Quality/Histogram/dcat-histogram-right.gif?la=en)\n",
    "\n",
    "\n",
    "* **Double-Peaked or Bimodal**\n",
    "\n",
    "    The bimodal distribution looks like the back of a two-humped camel. The outcomes of two processes with different distributions are combined in one set of data. For example, a distribution of production data from a two-shift operation might be bimodal, if each shift produces a different distribution of results. Stratification often reveals this problem.\n",
    "    ![Image of Yaktocat](https://asq.org/-/media/Images/Learn-About-Quality/Histogram/dcat-histogram-bimodal.gif?la=en)\n",
    "\n",
    "\n",
    "* **Plateau or Multimodal Distribution**\n",
    "\n",
    "    The plateau might be called a “multimodal distribution.” Several processes with normal distributions are combined. Because there are many peaks close together, the top of the distribution resembles a plateau.\n",
    "    ![Image of Yaktocat](https://asq.org/-/media/Images/Learn-About-Quality/Histogram/dcat-histogram-plateau.gif?la=en)\n",
    "\n",
    "\n",
    "* **Edge Peak Distribution**\n",
    "\n",
    "    The edge peak distribution looks like the normal distribution except that it has a large peak at one tail. Usually this is caused by faulty construction of the histogram, with data lumped together into a group labeled “greater than.”\n",
    "    ![Image of Yaktocat](https://asq.org/-/media/Images/Learn-About-Quality/Histogram/edge-peak-histogram.gif?la=en)\n",
    "\n",
    "* **Comb Distribution**\n",
    "\n",
    "    In a comb distribution, the bars are alternately tall and short. This distribution often results from rounded-off data and/or an incorrectly constructed histogram. For example, temperature data rounded off to the nearest 0.2 degree would show a comb shape if the bar width for the histogram were 0.1 degree.\n",
    "    ![Image of Yaktocat](https://asq.org/-/media/Images/Learn-About-Quality/Histogram/dcat-histogram-comb.gif?la=en)\n",
    "\n",
    "\n",
    "* **Truncated or Heart-Cut Distribution**\n",
    "\n",
    "    The truncated distribution looks like a normal distribution with the tails cut off. The supplier might be producing a normal distribution of material and then relying on inspection to separate what is within specification limits from what is out of spec. The resulting shipments to the customer from inside the specifications are the heart cut.\n",
    "    ![Image of Yaktocat](https://asq.org/-/media/Images/Learn-About-Quality/Histogram/dcat-histogram-truncated.gif?la=en)\n",
    "\n",
    "\n",
    "* **Dog Food Distribution**\n",
    "    The dog food distribution is missing something—results near the average. If a customer receives this kind of distribution, someone else is receiving a heart cut and the customer is left with the “dog food,” the odds and ends left over after the master’s meal. Even though what the customer receives is within specifications, the product falls into two clusters: one near the upper specification limit and one near the lower specification limit. This variation often causes problems in the customer’s process.\n",
    "    ![Image of Yaktocat](https://asq.org/-/media/Images/Learn-About-Quality/Histogram/dcat-histogram-dog-food.gif?la=en)\n",
    "    \n",
    "    \n",
    "**A histogram displays numerical data by grouping data into \"bins\" of equal width. Each bin is plotted as a bar whose height corresponds to how many data points are in that bin.\n",
    "Bins are also sometimes called \"intervals\", \"classes\", or \"buckets\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42f7c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c9a7a30",
   "metadata": {},
   "source": [
    "### 7. How do we deal with data outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c675970",
   "metadata": {},
   "source": [
    "Ans : An outlier is an observation that lies an abnormal distance from other values in a random sample from a population.\n",
    "\n",
    "![Image of Yaktocat](https://cxl.com/wp-content/uploads/2017/01/outlier.jpg)\n",
    "\n",
    "There are also different degrees of outliers:\n",
    "\n",
    "* Mild outliers lie beyond an “inner fence” on either side.\n",
    "* Extreme outliers are beyond an “outer fence.”\n",
    "\n",
    "### 5 ways to deal with outliers in data\n",
    "\n",
    "**1. Set up a filter in your testing tool**\n",
    "* Even though this has a little cost, filtering out outliers is worth it. You often discover significant effects that are simply “hidden” by outliers.\n",
    "    \n",
    "**2. Remove or change outliers during post-test analysis**\n",
    "* One way to account for this is simply to remove outliers, or trim your data set to exclude as many as you’d like.\n",
    "\n",
    "**3. Change the value of outliers**\n",
    "* Essentially, instead of removing outliers from the data, you change their values to something more representative of your data set. It’s a small but important distinction: When you trim data, the extreme values are discarded.\n",
    "\n",
    "**4. Consider the underlying distribution**\n",
    "* Traditional methods to calculate confidence intervals assume that the data follows a normal distribution, but as with certain metrics like average revenue per visitor, that usually isn’t the way reality works\n",
    "\n",
    "**5. Consider the value of mild outliers**\n",
    "* As exemplified by revenue per visitor, the underlying distribution is often non-normal. It’s common for a few big buyers to skew the data set toward the extremes. When this is the case, outlier detection falls prey to predictable inaccuracies—it detects outliers far more often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38033f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
